{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c84e49a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\topo_crack_detection\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e13081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Im_Seg_22(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = torch.nn.Parameter(torch.randn(()) , requires_grad=True)\n",
    "        self.b = torch.nn.Parameter(torch.randn(()) , requires_grad=True)\n",
    "        self.c = torch.nn.Parameter(torch.randn(()) , requires_grad=True)\n",
    "    \n",
    "    def forward(self , inp1 , inp2 , inp3):\n",
    "        return torch.sigmoid(self.a*inp1 + self.b*inp2 + self.c*inp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51915db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Im_Seg_22()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b113e4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', Parameter containing:\n",
      "tensor(0.5141, requires_grad=True))\n",
      "('b', Parameter containing:\n",
      "tensor(-1.3647, requires_grad=True))\n",
      "('c', Parameter containing:\n",
      "tensor(-0.0781, requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for m in model.named_parameters():\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a6026aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Im_Seg_22                                [3, 256, 256]             3\n",
       "==========================================================================================\n",
       "Total params: 3\n",
       "Trainable params: 3\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0\n",
       "==========================================================================================\n",
       "Input size (MB): 2.36\n",
       "Forward/backward pass size (MB): 1.57\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 3.93\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model , [(3,256,256) ,(3,256,256), (3,256,256) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "087e8582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ee3a2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6792], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.rand(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0aceb13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14516\\7437536.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\envs\\topo_crack_detection\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0mtotal_input_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m4.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[0mtotal_output_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtotal_output\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m4.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# x2 for gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0mtotal_params_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m4.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m     \u001b[0mtotal_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_params_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtotal_output_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtotal_input_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "summary(model , torch.rand(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6827cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Im_Seg_2(torch.nn.Module):\n",
    "    def __init__(self ,device, loc = \"./models/\" , trainable = set()):\n",
    "        super().__init__()\n",
    "        self.a = torch.nn.Parameter(torch.randn(()) , requires_grad=True)\n",
    "        self.b = torch.nn.Parameter(torch.randn(()) , requires_grad=True)\n",
    "        self.c = torch.nn.Parameter(torch.randn(()) , requires_grad=True)\n",
    "        #self.d = torch.nn.Parameter(torch.randn(()) , requires_grad=True)\n",
    "#         self.mod1 = UNet16() \n",
    "#         self.mod2 = UNet16() \n",
    "#         self.mod3 = UNet16() \n",
    "#         self.mod1.to(device = device)\n",
    "#         self.mod2.to(device = device)\n",
    "#         self.mod3.to(device = device)\n",
    "#         print(\"Reading model 1\")\n",
    "#         self.mod1.load_state_dict(torch.load(loc + \"model1.pt\", map_location=device))\n",
    "#         print(\"Reading model 2\")\n",
    "#         self.mod2.load_state_dict(torch.load(loc + \"model2.pt\", map_location=device))\n",
    "#         print(\"Reading model 3\")\n",
    "#         self.mod3.load_state_dict(torch.load(loc + \"model3.pt\", map_location=device))\n",
    "#         for k in self.mod1.named_parameters():\n",
    "#             k[1].requires_grad = True if k[0].split(\".\")[0] in trainable else False\n",
    "#         for k in self.mod2.named_parameters():\n",
    "#             k[1].requires_grad = True if k[0].split(\".\")[0] in trainable else False  \n",
    "#         for k in self.mod3.named_parameters():\n",
    "#             k[1].requires_grad = True if k[0].split(\".\")[0] in trainable else False  \n",
    "\n",
    "        #print(self.a.requires_grad , self.b.requires_grad , self.c.requires_grad)\n",
    "\n",
    "        #self.a.requires_grad = True \n",
    "        #self.b.requires_grad = True \n",
    "        #self.c.requires_grad = True \n",
    "        #print(len(list(self.check_state(1))) ,len(list(self.check_state(2))) , len(list(self.check_state(3))) )\n",
    "        #print(self.named_parameters())\n",
    "    def check_state(self , mod):\n",
    "        dic = {1 : self.mod1 , 2 : self.mod2 , 3 : self.mod3 }\n",
    "        return dic[mod].named_parameters()\n",
    "    \n",
    "    def forward(self , inp1):\n",
    "        return float(20.0)*torch.sigmoid(self.a*inp1 + self.b*inp2**2 + self.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7326ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Im_Seg_2(device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b841541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im_Seg_2()\n"
     ]
    }
   ],
   "source": [
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f099a52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = model2.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0e4f9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im_Seg_2()\n"
     ]
    }
   ],
   "source": [
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6c1f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import numpy as np\n",
    "#from torchinfo import summary\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision import transforms\n",
    "from network import UNet16\n",
    "\n",
    "\n",
    "class Im_Seg_2(torch.nn.Module):\n",
    "    def __init__(self ,device, loc = \"./models/\" , trainable = set()):\n",
    "        super().__init__()\n",
    "        self.a = torch.nn.Parameter(torch.randn(()) , requires_grad=True)\n",
    "        self.b = torch.nn.Parameter(torch.randn(()) , requires_grad=True)\n",
    "        self.c = torch.nn.Parameter(torch.randn(()) , requires_grad=True)\n",
    "        #self.d = torch.nn.Parameter(torch.randn(()) , requires_grad=True)\n",
    "        self.mod1 = UNet16() \n",
    "        self.mod2 = UNet16() \n",
    "        self.mod3 = UNet16() \n",
    "        self.mod1.to(device = device)\n",
    "        self.mod2.to(device = device)\n",
    "        self.mod3.to(device = device)\n",
    "        print(\"Reading model 1\")\n",
    "        self.mod1.load_state_dict(torch.load(loc + \"model1.pt\", map_location=device))\n",
    "        print(\"Reading model 2\")\n",
    "        self.mod2.load_state_dict(torch.load(loc + \"model2.pt\", map_location=device))\n",
    "        print(\"Reading model 3\")\n",
    "        self.mod3.load_state_dict(torch.load(loc + \"model3.pt\", map_location=device))\n",
    "#         for k in self.mod1.named_parameters():\n",
    "#             k[1].requires_grad = True if k[0].split(\".\")[0] in trainable else False\n",
    "#         for k in self.mod2.named_parameters():\n",
    "#             k[1].requires_grad = True if k[0].split(\".\")[0] in trainable else False  \n",
    "#         for k in self.mod3.named_parameters():\n",
    "#             k[1].requires_grad = True if k[0].split(\".\")[0] in trainable else False  \n",
    "\n",
    "        #print(self.a.requires_grad , self.b.requires_grad , self.c.requires_grad)\n",
    "\n",
    "        #self.a.requires_grad = True \n",
    "        #self.b.requires_grad = True \n",
    "        #self.c.requires_grad = True \n",
    "        #print(len(list(self.check_state(1))) ,len(list(self.check_state(2))) , len(list(self.check_state(3))) )\n",
    "    def check_state(self , mod):\n",
    "        dic = {1 : self.mod1 , 2 : self.mod2 , 3 : self.mod3 }\n",
    "        return dic[mod].named_parameters()\n",
    "    \n",
    "    def forward(self , inp1 , inp2 ,inp3):\n",
    "        #print(\"Yes , Yes , Yes\")\n",
    "        out1 = self.mod1(inp1)\n",
    "        out2 = self.mod2(inp2)\n",
    "        out3 = self.mod3(inp3)\n",
    "        #return float(20.0)*torch.sigmoid(out1 + out2 + out3)\n",
    "        return float(20.0)*torch.sigmoid(self.a*out1 + self.b*out2 + self.c*out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7734f0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\torch_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\torch_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model 1\n",
      "Reading model 2\n",
      "Reading model 3\n",
      "Using device cuda\n",
      "Using NVIDIA GeForce GTX 1050\n",
      "Im_Seg_2(\n",
      "  (mod1): UNet16(\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (encoder): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (27): ReLU(inplace=True)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv4): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv5): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (center): DecoderBlockV2(\n",
      "      (block): Sequential(\n",
      "        (0): Interpolate()\n",
      "        (1): ConvRelu(\n",
      "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvRelu(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dec5): DecoderBlockV2(\n",
      "      (block): Sequential(\n",
      "        (0): Interpolate()\n",
      "        (1): ConvRelu(\n",
      "          (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvRelu(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dec4): DecoderBlockV2(\n",
      "      (block): Sequential(\n",
      "        (0): Interpolate()\n",
      "        (1): ConvRelu(\n",
      "          (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvRelu(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dec3): DecoderBlockV2(\n",
      "      (block): Sequential(\n",
      "        (0): Interpolate()\n",
      "        (1): ConvRelu(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvRelu(\n",
      "          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dec2): DecoderBlockV2(\n",
      "      (block): Sequential(\n",
      "        (0): Interpolate()\n",
      "        (1): ConvRelu(\n",
      "          (conv): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvRelu(\n",
      "          (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dec1): ConvRelu(\n",
      "      (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (final): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (final2): Sigmoid()\n",
      "  )\n",
      "  (mod2): UNet16(\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (encoder): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (27): ReLU(inplace=True)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv4): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv5): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (center): DecoderBlockV2(\n",
      "      (block): Sequential(\n",
      "        (0): Interpolate()\n",
      "        (1): ConvRelu(\n",
      "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvRelu(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dec5): DecoderBlockV2(\n",
      "      (block): Sequential(\n",
      "        (0): Interpolate()\n",
      "        (1): ConvRelu(\n",
      "          (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvRelu(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dec4): DecoderBlockV2(\n",
      "      (block): Sequential(\n",
      "        (0): Interpolate()\n",
      "        (1): ConvRelu(\n",
      "          (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvRelu(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dec3): DecoderBlockV2(\n",
      "      (block): Sequential(\n",
      "        (0): Interpolate()\n",
      "        (1): ConvRelu(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvRelu(\n",
      "          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dec2): DecoderBlockV2(\n",
      "      (block): Sequential(\n",
      "        (0): Interpolate()\n",
      "        (1): ConvRelu(\n",
      "          (conv): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvRelu(\n",
      "          (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dec1): ConvRelu(\n",
      "      (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (final): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (final2): Sigmoid()\n",
      "  )\n",
      "  (mod3): UNet16(\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (encoder): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (27): ReLU(inplace=True)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv4): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (conv5): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (center): DecoderBlockV2(\n",
      "      (block): Sequential(\n",
      "        (0): Interpolate()\n",
      "        (1): ConvRelu(\n",
      "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvRelu(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dec5): DecoderBlockV2(\n",
      "      (block): Sequential(\n",
      "        (0): Interpolate()\n",
      "        (1): ConvRelu(\n",
      "          (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvRelu(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dec4): DecoderBlockV2(\n",
      "      (block): Sequential(\n",
      "        (0): Interpolate()\n",
      "        (1): ConvRelu(\n",
      "          (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvRelu(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dec3): DecoderBlockV2(\n",
      "      (block): Sequential(\n",
      "        (0): Interpolate()\n",
      "        (1): ConvRelu(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvRelu(\n",
      "          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dec2): DecoderBlockV2(\n",
      "      (block): Sequential(\n",
      "        (0): Interpolate()\n",
      "        (1): ConvRelu(\n",
      "          (conv): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): ConvRelu(\n",
      "          (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (activation): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dec1): ConvRelu(\n",
      "      (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (final): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (final2): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Sequential: 2, Conv2d: 3, ReLU: 3, Conv2d: 3, ReLU: 3, MaxPool2d: 2, Sequential: 2, Conv2d: 3, ReLU: 3, Conv2d: 3, ReLU: 3, MaxPool2d: 2, Sequential: 2, Conv2d: 3, ReLU: 3, Conv2d: 3, ReLU: 3, Conv2d: 3, ReLU: 3, MaxPool2d: 2, Sequential: 2, Conv2d: 3, ReLU: 3, Conv2d: 3, ReLU: 3, Conv2d: 3, ReLU: 3, MaxPool2d: 2, Sequential: 2, Conv2d: 3, ReLU: 3, Conv2d: 3, ReLU: 3, Conv2d: 3, ReLU: 3, MaxPool2d: 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch_env\\lib\\site-packages\\torchinfo\\torchinfo.py:295\u001b[0m, in \u001b[0;36mforward_pass\u001b[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 295\u001b[0m     _ \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39mx, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1538\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[1;32mIn[7], line 52\u001b[0m, in \u001b[0;36mIm_Seg_2.forward\u001b[1;34m(self, inp1, inp2, inp3)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m , inp1 , inp2 ,inp3):\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m#print(\"Yes , Yes , Yes\")\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     out1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmod1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     out2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmod2(inp2)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1538\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[1;32m~\\Desktop\\Proj_file\\Code_files\\Training_Scripts\\final_model\\network.py:286\u001b[0m, in \u001b[0;36mUNet16.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m conv5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv5(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(conv4))\n\u001b[1;32m--> 286\u001b[0m center \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv5\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m dec5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec5(torch\u001b[38;5;241m.\u001b[39mcat([center, conv5], \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1538\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[1;32m~\\Desktop\\Proj_file\\Code_files\\Training_Scripts\\final_model\\network.py:192\u001b[0m, in \u001b[0;36mDecoderBlockV2.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1538\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch_env\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1538\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[1;32m~\\Desktop\\Proj_file\\Code_files\\Training_Scripts\\final_model\\network.py:150\u001b[0m, in \u001b[0;36mInterpolate.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 150\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch_env\\lib\\site-packages\\torch\\nn\\functional.py:3970\u001b[0m, in \u001b[0;36minterpolate\u001b[1;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[0;32m   3969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 3970\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot 3D input, but bilinear mode needs 4D input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Got 3D input, but bilinear mode needs 4D input",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Show the model summary\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch_env\\lib\\site-packages\\torchinfo\\torchinfo.py:223\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m validate_user_params(\n\u001b[0;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[0;32m    218\u001b[0m )\n\u001b[0;32m    220\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[0;32m    221\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[0;32m    222\u001b[0m )\n\u001b[1;32m--> 223\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m forward_pass(\n\u001b[0;32m    224\u001b[0m     model, x, batch_dim, cache_forward_pass, device, model_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    225\u001b[0m )\n\u001b[0;32m    226\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[0;32m    227\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[0;32m    228\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[0;32m    229\u001b[0m )\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\torch_env\\lib\\site-packages\\torchinfo\\torchinfo.py:304\u001b[0m, in \u001b[0;36mforward_pass\u001b[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    303\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[1;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Sequential: 2, Conv2d: 3, ReLU: 3, Conv2d: 3, ReLU: 3, MaxPool2d: 2, Sequential: 2, Conv2d: 3, ReLU: 3, Conv2d: 3, ReLU: 3, MaxPool2d: 2, Sequential: 2, Conv2d: 3, ReLU: 3, Conv2d: 3, ReLU: 3, Conv2d: 3, ReLU: 3, MaxPool2d: 2, Sequential: 2, Conv2d: 3, ReLU: 3, Conv2d: 3, ReLU: 3, Conv2d: 3, ReLU: 3, MaxPool2d: 2, Sequential: 2, Conv2d: 3, ReLU: 3, Conv2d: 3, ReLU: 3, Conv2d: 3, ReLU: 3, MaxPool2d: 2]"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Im_Seg_2(device)\n",
    "print(f\"Using device {device}\")\n",
    "if torch.cuda.is_available() :\n",
    "    print(\"Using {}\".format(torch.cuda.get_device_name(0)))\n",
    "model=model.to(device)\n",
    "#Print the mode\n",
    "print(model)\n",
    "# Show the model summary\n",
    "summary(model , [(3, 256, 256), (3, 256, 256) , (3, 256, 256)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4ae40ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a True\n",
      "b True\n",
      "c True\n",
      "mod1.encoder.0.weight True\n",
      "mod1.encoder.0.bias True\n",
      "mod1.encoder.2.weight True\n",
      "mod1.encoder.2.bias True\n",
      "mod1.encoder.5.weight True\n",
      "mod1.encoder.5.bias True\n",
      "mod1.encoder.7.weight True\n",
      "mod1.encoder.7.bias True\n",
      "mod1.encoder.10.weight True\n",
      "mod1.encoder.10.bias True\n",
      "mod1.encoder.12.weight True\n",
      "mod1.encoder.12.bias True\n",
      "mod1.encoder.14.weight True\n",
      "mod1.encoder.14.bias True\n",
      "mod1.encoder.17.weight True\n",
      "mod1.encoder.17.bias True\n",
      "mod1.encoder.19.weight True\n",
      "mod1.encoder.19.bias True\n",
      "mod1.encoder.21.weight True\n",
      "mod1.encoder.21.bias True\n",
      "mod1.encoder.24.weight True\n",
      "mod1.encoder.24.bias True\n",
      "mod1.encoder.26.weight True\n",
      "mod1.encoder.26.bias True\n",
      "mod1.encoder.28.weight True\n",
      "mod1.encoder.28.bias True\n",
      "mod1.center.block.1.conv.weight True\n",
      "mod1.center.block.1.conv.bias True\n",
      "mod1.center.block.2.conv.weight True\n",
      "mod1.center.block.2.conv.bias True\n",
      "mod1.dec5.block.1.conv.weight True\n",
      "mod1.dec5.block.1.conv.bias True\n",
      "mod1.dec5.block.2.conv.weight True\n",
      "mod1.dec5.block.2.conv.bias True\n",
      "mod1.dec4.block.1.conv.weight True\n",
      "mod1.dec4.block.1.conv.bias True\n",
      "mod1.dec4.block.2.conv.weight True\n",
      "mod1.dec4.block.2.conv.bias True\n",
      "mod1.dec3.block.1.conv.weight True\n",
      "mod1.dec3.block.1.conv.bias True\n",
      "mod1.dec3.block.2.conv.weight True\n",
      "mod1.dec3.block.2.conv.bias True\n",
      "mod1.dec2.block.1.conv.weight True\n",
      "mod1.dec2.block.1.conv.bias True\n",
      "mod1.dec2.block.2.conv.weight True\n",
      "mod1.dec2.block.2.conv.bias True\n",
      "mod1.dec1.conv.weight True\n",
      "mod1.dec1.conv.bias True\n",
      "mod1.final.weight True\n",
      "mod1.final.bias True\n",
      "mod2.encoder.0.weight True\n",
      "mod2.encoder.0.bias True\n",
      "mod2.encoder.2.weight True\n",
      "mod2.encoder.2.bias True\n",
      "mod2.encoder.5.weight True\n",
      "mod2.encoder.5.bias True\n",
      "mod2.encoder.7.weight True\n",
      "mod2.encoder.7.bias True\n",
      "mod2.encoder.10.weight True\n",
      "mod2.encoder.10.bias True\n",
      "mod2.encoder.12.weight True\n",
      "mod2.encoder.12.bias True\n",
      "mod2.encoder.14.weight True\n",
      "mod2.encoder.14.bias True\n",
      "mod2.encoder.17.weight True\n",
      "mod2.encoder.17.bias True\n",
      "mod2.encoder.19.weight True\n",
      "mod2.encoder.19.bias True\n",
      "mod2.encoder.21.weight True\n",
      "mod2.encoder.21.bias True\n",
      "mod2.encoder.24.weight True\n",
      "mod2.encoder.24.bias True\n",
      "mod2.encoder.26.weight True\n",
      "mod2.encoder.26.bias True\n",
      "mod2.encoder.28.weight True\n",
      "mod2.encoder.28.bias True\n",
      "mod2.center.block.1.conv.weight True\n",
      "mod2.center.block.1.conv.bias True\n",
      "mod2.center.block.2.conv.weight True\n",
      "mod2.center.block.2.conv.bias True\n",
      "mod2.dec5.block.1.conv.weight True\n",
      "mod2.dec5.block.1.conv.bias True\n",
      "mod2.dec5.block.2.conv.weight True\n",
      "mod2.dec5.block.2.conv.bias True\n",
      "mod2.dec4.block.1.conv.weight True\n",
      "mod2.dec4.block.1.conv.bias True\n",
      "mod2.dec4.block.2.conv.weight True\n",
      "mod2.dec4.block.2.conv.bias True\n",
      "mod2.dec3.block.1.conv.weight True\n",
      "mod2.dec3.block.1.conv.bias True\n",
      "mod2.dec3.block.2.conv.weight True\n",
      "mod2.dec3.block.2.conv.bias True\n",
      "mod2.dec2.block.1.conv.weight True\n",
      "mod2.dec2.block.1.conv.bias True\n",
      "mod2.dec2.block.2.conv.weight True\n",
      "mod2.dec2.block.2.conv.bias True\n",
      "mod2.dec1.conv.weight True\n",
      "mod2.dec1.conv.bias True\n",
      "mod2.final.weight True\n",
      "mod2.final.bias True\n",
      "mod3.encoder.0.weight True\n",
      "mod3.encoder.0.bias True\n",
      "mod3.encoder.2.weight True\n",
      "mod3.encoder.2.bias True\n",
      "mod3.encoder.5.weight True\n",
      "mod3.encoder.5.bias True\n",
      "mod3.encoder.7.weight True\n",
      "mod3.encoder.7.bias True\n",
      "mod3.encoder.10.weight True\n",
      "mod3.encoder.10.bias True\n",
      "mod3.encoder.12.weight True\n",
      "mod3.encoder.12.bias True\n",
      "mod3.encoder.14.weight True\n",
      "mod3.encoder.14.bias True\n",
      "mod3.encoder.17.weight True\n",
      "mod3.encoder.17.bias True\n",
      "mod3.encoder.19.weight True\n",
      "mod3.encoder.19.bias True\n",
      "mod3.encoder.21.weight True\n",
      "mod3.encoder.21.bias True\n",
      "mod3.encoder.24.weight True\n",
      "mod3.encoder.24.bias True\n",
      "mod3.encoder.26.weight True\n",
      "mod3.encoder.26.bias True\n",
      "mod3.encoder.28.weight True\n",
      "mod3.encoder.28.bias True\n",
      "mod3.center.block.1.conv.weight True\n",
      "mod3.center.block.1.conv.bias True\n",
      "mod3.center.block.2.conv.weight True\n",
      "mod3.center.block.2.conv.bias True\n",
      "mod3.dec5.block.1.conv.weight True\n",
      "mod3.dec5.block.1.conv.bias True\n",
      "mod3.dec5.block.2.conv.weight True\n",
      "mod3.dec5.block.2.conv.bias True\n",
      "mod3.dec4.block.1.conv.weight True\n",
      "mod3.dec4.block.1.conv.bias True\n",
      "mod3.dec4.block.2.conv.weight True\n",
      "mod3.dec4.block.2.conv.bias True\n",
      "mod3.dec3.block.1.conv.weight True\n",
      "mod3.dec3.block.1.conv.bias True\n",
      "mod3.dec3.block.2.conv.weight True\n",
      "mod3.dec3.block.2.conv.bias True\n",
      "mod3.dec2.block.1.conv.weight True\n",
      "mod3.dec2.block.1.conv.bias True\n",
      "mod3.dec2.block.2.conv.weight True\n",
      "mod3.dec2.block.2.conv.bias True\n",
      "mod3.dec1.conv.weight True\n",
      "mod3.dec1.conv.bias True\n",
      "mod3.final.weight True\n",
      "mod3.final.bias True\n"
     ]
    }
   ],
   "source": [
    "for m in model.named_parameters():\n",
    "    print(m[0] , m[1].requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "70b5c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    #table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        params = parameter.numel()\n",
    "#         table.add_row([name, params])\n",
    "        print([name, params])\n",
    "        total_params += params\n",
    "    #print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe0bd9e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prettytable'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14516\\1363011346.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mprettytable\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPrettyTable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'prettytable'"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e25e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "641be5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 1]\n",
      "['b', 1]\n",
      "['c', 1]\n",
      "['mod1.encoder.0.weight', 1728]\n",
      "['mod1.encoder.0.bias', 64]\n",
      "['mod1.encoder.2.weight', 36864]\n",
      "['mod1.encoder.2.bias', 64]\n",
      "['mod1.encoder.5.weight', 73728]\n",
      "['mod1.encoder.5.bias', 128]\n",
      "['mod1.encoder.7.weight', 147456]\n",
      "['mod1.encoder.7.bias', 128]\n",
      "['mod1.encoder.10.weight', 294912]\n",
      "['mod1.encoder.10.bias', 256]\n",
      "['mod1.encoder.12.weight', 589824]\n",
      "['mod1.encoder.12.bias', 256]\n",
      "['mod1.encoder.14.weight', 589824]\n",
      "['mod1.encoder.14.bias', 256]\n",
      "['mod1.encoder.17.weight', 1179648]\n",
      "['mod1.encoder.17.bias', 512]\n",
      "['mod1.encoder.19.weight', 2359296]\n",
      "['mod1.encoder.19.bias', 512]\n",
      "['mod1.encoder.21.weight', 2359296]\n",
      "['mod1.encoder.21.bias', 512]\n",
      "['mod1.encoder.24.weight', 2359296]\n",
      "['mod1.encoder.24.bias', 512]\n",
      "['mod1.encoder.26.weight', 2359296]\n",
      "['mod1.encoder.26.bias', 512]\n",
      "['mod1.encoder.28.weight', 2359296]\n",
      "['mod1.encoder.28.bias', 512]\n",
      "['mod1.center.block.1.conv.weight', 2359296]\n",
      "['mod1.center.block.1.conv.bias', 512]\n",
      "['mod1.center.block.2.conv.weight', 1179648]\n",
      "['mod1.center.block.2.conv.bias', 256]\n",
      "['mod1.dec5.block.1.conv.weight', 3538944]\n",
      "['mod1.dec5.block.1.conv.bias', 512]\n",
      "['mod1.dec5.block.2.conv.weight', 1179648]\n",
      "['mod1.dec5.block.2.conv.bias', 256]\n",
      "['mod1.dec4.block.1.conv.weight', 3538944]\n",
      "['mod1.dec4.block.1.conv.bias', 512]\n",
      "['mod1.dec4.block.2.conv.weight', 1179648]\n",
      "['mod1.dec4.block.2.conv.bias', 256]\n",
      "['mod1.dec3.block.1.conv.weight', 1179648]\n",
      "['mod1.dec3.block.1.conv.bias', 256]\n",
      "['mod1.dec3.block.2.conv.weight', 147456]\n",
      "['mod1.dec3.block.2.conv.bias', 64]\n",
      "['mod1.dec2.block.1.conv.weight', 221184]\n",
      "['mod1.dec2.block.1.conv.bias', 128]\n",
      "['mod1.dec2.block.2.conv.weight', 36864]\n",
      "['mod1.dec2.block.2.conv.bias', 32]\n",
      "['mod1.dec1.conv.weight', 27648]\n",
      "['mod1.dec1.conv.bias', 32]\n",
      "['mod1.final.weight', 32]\n",
      "['mod1.final.bias', 1]\n",
      "['mod2.encoder.0.weight', 1728]\n",
      "['mod2.encoder.0.bias', 64]\n",
      "['mod2.encoder.2.weight', 36864]\n",
      "['mod2.encoder.2.bias', 64]\n",
      "['mod2.encoder.5.weight', 73728]\n",
      "['mod2.encoder.5.bias', 128]\n",
      "['mod2.encoder.7.weight', 147456]\n",
      "['mod2.encoder.7.bias', 128]\n",
      "['mod2.encoder.10.weight', 294912]\n",
      "['mod2.encoder.10.bias', 256]\n",
      "['mod2.encoder.12.weight', 589824]\n",
      "['mod2.encoder.12.bias', 256]\n",
      "['mod2.encoder.14.weight', 589824]\n",
      "['mod2.encoder.14.bias', 256]\n",
      "['mod2.encoder.17.weight', 1179648]\n",
      "['mod2.encoder.17.bias', 512]\n",
      "['mod2.encoder.19.weight', 2359296]\n",
      "['mod2.encoder.19.bias', 512]\n",
      "['mod2.encoder.21.weight', 2359296]\n",
      "['mod2.encoder.21.bias', 512]\n",
      "['mod2.encoder.24.weight', 2359296]\n",
      "['mod2.encoder.24.bias', 512]\n",
      "['mod2.encoder.26.weight', 2359296]\n",
      "['mod2.encoder.26.bias', 512]\n",
      "['mod2.encoder.28.weight', 2359296]\n",
      "['mod2.encoder.28.bias', 512]\n",
      "['mod2.center.block.1.conv.weight', 2359296]\n",
      "['mod2.center.block.1.conv.bias', 512]\n",
      "['mod2.center.block.2.conv.weight', 1179648]\n",
      "['mod2.center.block.2.conv.bias', 256]\n",
      "['mod2.dec5.block.1.conv.weight', 3538944]\n",
      "['mod2.dec5.block.1.conv.bias', 512]\n",
      "['mod2.dec5.block.2.conv.weight', 1179648]\n",
      "['mod2.dec5.block.2.conv.bias', 256]\n",
      "['mod2.dec4.block.1.conv.weight', 3538944]\n",
      "['mod2.dec4.block.1.conv.bias', 512]\n",
      "['mod2.dec4.block.2.conv.weight', 1179648]\n",
      "['mod2.dec4.block.2.conv.bias', 256]\n",
      "['mod2.dec3.block.1.conv.weight', 1179648]\n",
      "['mod2.dec3.block.1.conv.bias', 256]\n",
      "['mod2.dec3.block.2.conv.weight', 147456]\n",
      "['mod2.dec3.block.2.conv.bias', 64]\n",
      "['mod2.dec2.block.1.conv.weight', 221184]\n",
      "['mod2.dec2.block.1.conv.bias', 128]\n",
      "['mod2.dec2.block.2.conv.weight', 36864]\n",
      "['mod2.dec2.block.2.conv.bias', 32]\n",
      "['mod2.dec1.conv.weight', 27648]\n",
      "['mod2.dec1.conv.bias', 32]\n",
      "['mod2.final.weight', 32]\n",
      "['mod2.final.bias', 1]\n",
      "['mod3.encoder.0.weight', 1728]\n",
      "['mod3.encoder.0.bias', 64]\n",
      "['mod3.encoder.2.weight', 36864]\n",
      "['mod3.encoder.2.bias', 64]\n",
      "['mod3.encoder.5.weight', 73728]\n",
      "['mod3.encoder.5.bias', 128]\n",
      "['mod3.encoder.7.weight', 147456]\n",
      "['mod3.encoder.7.bias', 128]\n",
      "['mod3.encoder.10.weight', 294912]\n",
      "['mod3.encoder.10.bias', 256]\n",
      "['mod3.encoder.12.weight', 589824]\n",
      "['mod3.encoder.12.bias', 256]\n",
      "['mod3.encoder.14.weight', 589824]\n",
      "['mod3.encoder.14.bias', 256]\n",
      "['mod3.encoder.17.weight', 1179648]\n",
      "['mod3.encoder.17.bias', 512]\n",
      "['mod3.encoder.19.weight', 2359296]\n",
      "['mod3.encoder.19.bias', 512]\n",
      "['mod3.encoder.21.weight', 2359296]\n",
      "['mod3.encoder.21.bias', 512]\n",
      "['mod3.encoder.24.weight', 2359296]\n",
      "['mod3.encoder.24.bias', 512]\n",
      "['mod3.encoder.26.weight', 2359296]\n",
      "['mod3.encoder.26.bias', 512]\n",
      "['mod3.encoder.28.weight', 2359296]\n",
      "['mod3.encoder.28.bias', 512]\n",
      "['mod3.center.block.1.conv.weight', 2359296]\n",
      "['mod3.center.block.1.conv.bias', 512]\n",
      "['mod3.center.block.2.conv.weight', 1179648]\n",
      "['mod3.center.block.2.conv.bias', 256]\n",
      "['mod3.dec5.block.1.conv.weight', 3538944]\n",
      "['mod3.dec5.block.1.conv.bias', 512]\n",
      "['mod3.dec5.block.2.conv.weight', 1179648]\n",
      "['mod3.dec5.block.2.conv.bias', 256]\n",
      "['mod3.dec4.block.1.conv.weight', 3538944]\n",
      "['mod3.dec4.block.1.conv.bias', 512]\n",
      "['mod3.dec4.block.2.conv.weight', 1179648]\n",
      "['mod3.dec4.block.2.conv.bias', 256]\n",
      "['mod3.dec3.block.1.conv.weight', 1179648]\n",
      "['mod3.dec3.block.1.conv.bias', 256]\n",
      "['mod3.dec3.block.2.conv.weight', 147456]\n",
      "['mod3.dec3.block.2.conv.bias', 64]\n",
      "['mod3.dec2.block.1.conv.weight', 221184]\n",
      "['mod3.dec2.block.1.conv.bias', 128]\n",
      "['mod3.dec2.block.2.conv.weight', 36864]\n",
      "['mod3.dec2.block.2.conv.bias', 32]\n",
      "['mod3.dec1.conv.weight', 27648]\n",
      "['mod3.dec1.conv.bias', 32]\n",
      "['mod3.final.weight', 32]\n",
      "['mod3.final.bias', 1]\n",
      "Total Trainable Params: 87919398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87919398"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c0965068",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = UNet16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "02a1ec83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet16(\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (center): DecoderBlockV2(\n",
       "    (block): Sequential(\n",
       "      (0): Interpolate()\n",
       "      (1): ConvRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvRelu(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec5): DecoderBlockV2(\n",
       "    (block): Sequential(\n",
       "      (0): Interpolate()\n",
       "      (1): ConvRelu(\n",
       "        (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvRelu(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec4): DecoderBlockV2(\n",
       "    (block): Sequential(\n",
       "      (0): Interpolate()\n",
       "      (1): ConvRelu(\n",
       "        (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvRelu(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec3): DecoderBlockV2(\n",
       "    (block): Sequential(\n",
       "      (0): Interpolate()\n",
       "      (1): ConvRelu(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec2): DecoderBlockV2(\n",
       "    (block): Sequential(\n",
       "      (0): Interpolate()\n",
       "      (1): ConvRelu(\n",
       "        (conv): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvRelu(\n",
       "        (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec1): ConvRelu(\n",
       "    (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (activation): ReLU(inplace=True)\n",
       "  )\n",
       "  (final): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (final2): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "afdec45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           1,792\n",
      "            Conv2d-2         [-1, 64, 256, 256]           1,792\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "              ReLU-4         [-1, 64, 256, 256]               0\n",
      "              ReLU-5         [-1, 64, 256, 256]               0\n",
      "              ReLU-6         [-1, 64, 256, 256]               0\n",
      "              ReLU-7         [-1, 64, 256, 256]               0\n",
      "              ReLU-8         [-1, 64, 256, 256]               0\n",
      "            Conv2d-9         [-1, 64, 256, 256]          36,928\n",
      "           Conv2d-10         [-1, 64, 256, 256]          36,928\n",
      "             ReLU-11         [-1, 64, 256, 256]               0\n",
      "             ReLU-12         [-1, 64, 256, 256]               0\n",
      "             ReLU-13         [-1, 64, 256, 256]               0\n",
      "             ReLU-14         [-1, 64, 256, 256]               0\n",
      "             ReLU-15         [-1, 64, 256, 256]               0\n",
      "             ReLU-16         [-1, 64, 256, 256]               0\n",
      "        MaxPool2d-17         [-1, 64, 128, 128]               0\n",
      "           Conv2d-18        [-1, 128, 128, 128]          73,856\n",
      "           Conv2d-19        [-1, 128, 128, 128]          73,856\n",
      "             ReLU-20        [-1, 128, 128, 128]               0\n",
      "             ReLU-21        [-1, 128, 128, 128]               0\n",
      "             ReLU-22        [-1, 128, 128, 128]               0\n",
      "             ReLU-23        [-1, 128, 128, 128]               0\n",
      "             ReLU-24        [-1, 128, 128, 128]               0\n",
      "             ReLU-25        [-1, 128, 128, 128]               0\n",
      "           Conv2d-26        [-1, 128, 128, 128]         147,584\n",
      "           Conv2d-27        [-1, 128, 128, 128]         147,584\n",
      "             ReLU-28        [-1, 128, 128, 128]               0\n",
      "             ReLU-29        [-1, 128, 128, 128]               0\n",
      "             ReLU-30        [-1, 128, 128, 128]               0\n",
      "             ReLU-31        [-1, 128, 128, 128]               0\n",
      "             ReLU-32        [-1, 128, 128, 128]               0\n",
      "             ReLU-33        [-1, 128, 128, 128]               0\n",
      "        MaxPool2d-34          [-1, 128, 64, 64]               0\n",
      "           Conv2d-35          [-1, 256, 64, 64]         295,168\n",
      "           Conv2d-36          [-1, 256, 64, 64]         295,168\n",
      "             ReLU-37          [-1, 256, 64, 64]               0\n",
      "             ReLU-38          [-1, 256, 64, 64]               0\n",
      "             ReLU-39          [-1, 256, 64, 64]               0\n",
      "             ReLU-40          [-1, 256, 64, 64]               0\n",
      "             ReLU-41          [-1, 256, 64, 64]               0\n",
      "             ReLU-42          [-1, 256, 64, 64]               0\n",
      "           Conv2d-43          [-1, 256, 64, 64]         590,080\n",
      "           Conv2d-44          [-1, 256, 64, 64]         590,080\n",
      "             ReLU-45          [-1, 256, 64, 64]               0\n",
      "             ReLU-46          [-1, 256, 64, 64]               0\n",
      "             ReLU-47          [-1, 256, 64, 64]               0\n",
      "             ReLU-48          [-1, 256, 64, 64]               0\n",
      "             ReLU-49          [-1, 256, 64, 64]               0\n",
      "             ReLU-50          [-1, 256, 64, 64]               0\n",
      "           Conv2d-51          [-1, 256, 64, 64]         590,080\n",
      "           Conv2d-52          [-1, 256, 64, 64]         590,080\n",
      "             ReLU-53          [-1, 256, 64, 64]               0\n",
      "             ReLU-54          [-1, 256, 64, 64]               0\n",
      "             ReLU-55          [-1, 256, 64, 64]               0\n",
      "             ReLU-56          [-1, 256, 64, 64]               0\n",
      "             ReLU-57          [-1, 256, 64, 64]               0\n",
      "             ReLU-58          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-59          [-1, 256, 32, 32]               0\n",
      "           Conv2d-60          [-1, 512, 32, 32]       1,180,160\n",
      "           Conv2d-61          [-1, 512, 32, 32]       1,180,160\n",
      "             ReLU-62          [-1, 512, 32, 32]               0\n",
      "             ReLU-63          [-1, 512, 32, 32]               0\n",
      "             ReLU-64          [-1, 512, 32, 32]               0\n",
      "             ReLU-65          [-1, 512, 32, 32]               0\n",
      "             ReLU-66          [-1, 512, 32, 32]               0\n",
      "             ReLU-67          [-1, 512, 32, 32]               0\n",
      "           Conv2d-68          [-1, 512, 32, 32]       2,359,808\n",
      "           Conv2d-69          [-1, 512, 32, 32]       2,359,808\n",
      "             ReLU-70          [-1, 512, 32, 32]               0\n",
      "             ReLU-71          [-1, 512, 32, 32]               0\n",
      "             ReLU-72          [-1, 512, 32, 32]               0\n",
      "             ReLU-73          [-1, 512, 32, 32]               0\n",
      "             ReLU-74          [-1, 512, 32, 32]               0\n",
      "             ReLU-75          [-1, 512, 32, 32]               0\n",
      "           Conv2d-76          [-1, 512, 32, 32]       2,359,808\n",
      "           Conv2d-77          [-1, 512, 32, 32]       2,359,808\n",
      "             ReLU-78          [-1, 512, 32, 32]               0\n",
      "             ReLU-79          [-1, 512, 32, 32]               0\n",
      "             ReLU-80          [-1, 512, 32, 32]               0\n",
      "             ReLU-81          [-1, 512, 32, 32]               0\n",
      "             ReLU-82          [-1, 512, 32, 32]               0\n",
      "             ReLU-83          [-1, 512, 32, 32]               0\n",
      "        MaxPool2d-84          [-1, 512, 16, 16]               0\n",
      "           Conv2d-85          [-1, 512, 16, 16]       2,359,808\n",
      "           Conv2d-86          [-1, 512, 16, 16]       2,359,808\n",
      "             ReLU-87          [-1, 512, 16, 16]               0\n",
      "             ReLU-88          [-1, 512, 16, 16]               0\n",
      "             ReLU-89          [-1, 512, 16, 16]               0\n",
      "             ReLU-90          [-1, 512, 16, 16]               0\n",
      "             ReLU-91          [-1, 512, 16, 16]               0\n",
      "             ReLU-92          [-1, 512, 16, 16]               0\n",
      "           Conv2d-93          [-1, 512, 16, 16]       2,359,808\n",
      "           Conv2d-94          [-1, 512, 16, 16]       2,359,808\n",
      "             ReLU-95          [-1, 512, 16, 16]               0\n",
      "             ReLU-96          [-1, 512, 16, 16]               0\n",
      "             ReLU-97          [-1, 512, 16, 16]               0\n",
      "             ReLU-98          [-1, 512, 16, 16]               0\n",
      "             ReLU-99          [-1, 512, 16, 16]               0\n",
      "            ReLU-100          [-1, 512, 16, 16]               0\n",
      "          Conv2d-101          [-1, 512, 16, 16]       2,359,808\n",
      "          Conv2d-102          [-1, 512, 16, 16]       2,359,808\n",
      "            ReLU-103          [-1, 512, 16, 16]               0\n",
      "            ReLU-104          [-1, 512, 16, 16]               0\n",
      "            ReLU-105          [-1, 512, 16, 16]               0\n",
      "            ReLU-106          [-1, 512, 16, 16]               0\n",
      "            ReLU-107          [-1, 512, 16, 16]               0\n",
      "            ReLU-108          [-1, 512, 16, 16]               0\n",
      "       MaxPool2d-109            [-1, 512, 8, 8]               0\n",
      "     Interpolate-110          [-1, 512, 16, 16]               0\n",
      "          Conv2d-111          [-1, 512, 16, 16]       2,359,808\n",
      "            ReLU-112          [-1, 512, 16, 16]               0\n",
      "        ConvRelu-113          [-1, 512, 16, 16]               0\n",
      "          Conv2d-114          [-1, 256, 16, 16]       1,179,904\n",
      "            ReLU-115          [-1, 256, 16, 16]               0\n",
      "        ConvRelu-116          [-1, 256, 16, 16]               0\n",
      "  DecoderBlockV2-117          [-1, 256, 16, 16]               0\n",
      "     Interpolate-118          [-1, 768, 32, 32]               0\n",
      "          Conv2d-119          [-1, 512, 32, 32]       3,539,456\n",
      "            ReLU-120          [-1, 512, 32, 32]               0\n",
      "        ConvRelu-121          [-1, 512, 32, 32]               0\n",
      "          Conv2d-122          [-1, 256, 32, 32]       1,179,904\n",
      "            ReLU-123          [-1, 256, 32, 32]               0\n",
      "        ConvRelu-124          [-1, 256, 32, 32]               0\n",
      "  DecoderBlockV2-125          [-1, 256, 32, 32]               0\n",
      "     Interpolate-126          [-1, 768, 64, 64]               0\n",
      "          Conv2d-127          [-1, 512, 64, 64]       3,539,456\n",
      "            ReLU-128          [-1, 512, 64, 64]               0\n",
      "        ConvRelu-129          [-1, 512, 64, 64]               0\n",
      "          Conv2d-130          [-1, 256, 64, 64]       1,179,904\n",
      "            ReLU-131          [-1, 256, 64, 64]               0\n",
      "        ConvRelu-132          [-1, 256, 64, 64]               0\n",
      "  DecoderBlockV2-133          [-1, 256, 64, 64]               0\n",
      "     Interpolate-134        [-1, 512, 128, 128]               0\n",
      "          Conv2d-135        [-1, 256, 128, 128]       1,179,904\n",
      "            ReLU-136        [-1, 256, 128, 128]               0\n",
      "        ConvRelu-137        [-1, 256, 128, 128]               0\n",
      "          Conv2d-138         [-1, 64, 128, 128]         147,520\n",
      "            ReLU-139         [-1, 64, 128, 128]               0\n",
      "        ConvRelu-140         [-1, 64, 128, 128]               0\n",
      "  DecoderBlockV2-141         [-1, 64, 128, 128]               0\n",
      "     Interpolate-142        [-1, 192, 256, 256]               0\n",
      "          Conv2d-143        [-1, 128, 256, 256]         221,312\n",
      "            ReLU-144        [-1, 128, 256, 256]               0\n",
      "        ConvRelu-145        [-1, 128, 256, 256]               0\n",
      "          Conv2d-146         [-1, 32, 256, 256]          36,896\n",
      "            ReLU-147         [-1, 32, 256, 256]               0\n",
      "        ConvRelu-148         [-1, 32, 256, 256]               0\n",
      "  DecoderBlockV2-149         [-1, 32, 256, 256]               0\n",
      "          Conv2d-150         [-1, 32, 256, 256]          27,680\n",
      "            ReLU-151         [-1, 32, 256, 256]               0\n",
      "        ConvRelu-152         [-1, 32, 256, 256]               0\n",
      "          Conv2d-153          [-1, 1, 256, 256]              33\n",
      "         Sigmoid-154          [-1, 1, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 44,021,153\n",
      "Trainable params: 44,021,153\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 1824.25\n",
      "Params size (MB): 167.93\n",
      "Estimated Total Size (MB): 1992.93\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model2 , (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f1673d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encoder.0.weight', 1728]\n",
      "['encoder.0.bias', 64]\n",
      "['encoder.2.weight', 36864]\n",
      "['encoder.2.bias', 64]\n",
      "['encoder.5.weight', 73728]\n",
      "['encoder.5.bias', 128]\n",
      "['encoder.7.weight', 147456]\n",
      "['encoder.7.bias', 128]\n",
      "['encoder.10.weight', 294912]\n",
      "['encoder.10.bias', 256]\n",
      "['encoder.12.weight', 589824]\n",
      "['encoder.12.bias', 256]\n",
      "['encoder.14.weight', 589824]\n",
      "['encoder.14.bias', 256]\n",
      "['encoder.17.weight', 1179648]\n",
      "['encoder.17.bias', 512]\n",
      "['encoder.19.weight', 2359296]\n",
      "['encoder.19.bias', 512]\n",
      "['encoder.21.weight', 2359296]\n",
      "['encoder.21.bias', 512]\n",
      "['encoder.24.weight', 2359296]\n",
      "['encoder.24.bias', 512]\n",
      "['encoder.26.weight', 2359296]\n",
      "['encoder.26.bias', 512]\n",
      "['encoder.28.weight', 2359296]\n",
      "['encoder.28.bias', 512]\n",
      "['center.block.1.conv.weight', 2359296]\n",
      "['center.block.1.conv.bias', 512]\n",
      "['center.block.2.conv.weight', 1179648]\n",
      "['center.block.2.conv.bias', 256]\n",
      "['dec5.block.1.conv.weight', 3538944]\n",
      "['dec5.block.1.conv.bias', 512]\n",
      "['dec5.block.2.conv.weight', 1179648]\n",
      "['dec5.block.2.conv.bias', 256]\n",
      "['dec4.block.1.conv.weight', 3538944]\n",
      "['dec4.block.1.conv.bias', 512]\n",
      "['dec4.block.2.conv.weight', 1179648]\n",
      "['dec4.block.2.conv.bias', 256]\n",
      "['dec3.block.1.conv.weight', 1179648]\n",
      "['dec3.block.1.conv.bias', 256]\n",
      "['dec3.block.2.conv.weight', 147456]\n",
      "['dec3.block.2.conv.bias', 64]\n",
      "['dec2.block.1.conv.weight', 221184]\n",
      "['dec2.block.1.conv.bias', 128]\n",
      "['dec2.block.2.conv.weight', 36864]\n",
      "['dec2.block.2.conv.bias', 32]\n",
      "['dec1.conv.weight', 27648]\n",
      "['dec1.conv.bias', 32]\n",
      "['final.weight', 32]\n",
      "['final.bias', 1]\n",
      "Total Trainable Params: 29306465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29306465"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d41b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2train_i=\"./data/_inp_/train\"\n",
    "path2train_i2=\"./data/_inp_2/train\"\n",
    "path2train_i3=\"./data/_inp_3/train\"\n",
    "path2train_m=\"./data/_out_/train\"\n",
    "#validation\n",
    "path2valid_i=\"./data/_inp_/val\"\n",
    "path2valid_i2=\"./data/_inp_2/val\"\n",
    "path2valid_i3=\"./data/_inp_3/val\"\n",
    "path2valid_m=\"./data/_out_/val\" \n",
    "#test\n",
    "path2test_i=\"./data/_inp_/test\"\n",
    "path2test_i2=\"./data/_inp_2/test\"\n",
    "path2test_i3=\"./data/_inp_/test\"\n",
    "path2test_m=\"./data/_out_/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06eafc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_set import open_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85604ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=open_dataset(path2train_i , path2train_i2 , path2train_i3 , path2data_m=path2train_m, transform='train')\n",
    "valid_ds=open_dataset(path2valid_i , path2valid_i2 , path2valid_i3 , path2data_m=path2valid_m, transform='val')\n",
    "test_ds=open_dataset(path2test_i , path2test_i2 , path2test_i3, path2data_m=path2test_m, transform='val')\n",
    "\n",
    "#Create Data Loader\n",
    "train_dl = DataLoader(train_ds, batch_size=3, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=3, shuffle=False) \n",
    "test_dl = DataLoader(test_ds, batch_size=3, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02ef87fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13155"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebebdae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39465"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bcb88e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "random.seed(100)\n",
    "\n",
    "#Define the open_dataset class:\n",
    "class open_dataset(Dataset):\n",
    "    def __init__(self, path2data_i , path2data_i2 , path2data_i3, path2data_m=None, transform=None):      \n",
    "\n",
    "        imgsList=[pp for pp in os.listdir(path2data_i)]\n",
    "        imgsList.sort()\n",
    "        imgsList = tuple(imgsList)\n",
    "        imgsList2=[pp for pp in os.listdir(path2data_i2)]\n",
    "        imgsList2.sort()\n",
    "        imgsList2 = tuple(imgsList2)\n",
    "        imgsList3=[pp for pp in os.listdir(path2data_i3)]\n",
    "        imgsList3.sort()\n",
    "        imgsList3 = tuple(imgsList3)\n",
    "        if transform!=\"test\":\n",
    "            anntsList=[pp for pp in os.listdir(path2data_m)]\n",
    "            anntsList.sort()\n",
    "            anntsList = tuple(anntsList)\n",
    "        if transform!=\"test\":\n",
    "            assert imgsList == anntsList and imgsList2 == anntsList and imgsList3 == anntsList, \"Train sets inputs and outputs dont coincide .\"\n",
    "\n",
    "        self.path2imgs = [os.path.join(path2data_i, fn) for fn in imgsList] \n",
    "        self.path2imgs2 = [os.path.join(path2data_i2, fn) for fn in imgsList2] \n",
    "        self.path2imgs3 = [os.path.join(path2data_i3, fn) for fn in imgsList3] \n",
    "\n",
    "        if transform!=\"test\":\n",
    "            self.path2annts= [os.path.join(path2data_m, fn) for fn in anntsList]\n",
    "\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path2imgs)\n",
    "      \n",
    "    def __getitem__(self, idx):\n",
    "        path2img = self.path2imgs[idx]\n",
    "        path2img2 = self.path2imgs2[idx]\n",
    "        path2img3 = self.path2imgs3[idx]\n",
    "        img = Image.open(path2img).convert('RGB')\n",
    "        img2 = Image.open(path2img2).convert('RGB')\n",
    "        img3 = Image.open(path2img3).convert('RGB')\n",
    "        if self.transform!=\"test\":\n",
    "            path2annt = self.path2annts[idx]\n",
    "            mask = Image.open(path2annt)\n",
    "                \n",
    "        if self.transform=='train':\n",
    "                # if random.random()<.5:\n",
    "                #     img = TF.hflip(img)\n",
    "                #     mask = TF.hflip(mask)\n",
    "                # if random.random()<.5:\n",
    "                #     img = TF.vflip(img)\n",
    "                #     mask = TF.vflip(mask)\n",
    "                if random.random()<.5:\n",
    "                    img = TF.adjust_brightness(img,brightness_factor=.5)\n",
    "                    img2 = TF.adjust_brightness(img2,brightness_factor=.5)\n",
    "                    img3 = TF.adjust_brightness(img3,brightness_factor=.5)\n",
    "                if random.random()<.5:\n",
    "                    img = TF.adjust_contrast(img,contrast_factor=.4)\n",
    "                    img2 = TF.adjust_contrast(img2,contrast_factor=.4)\n",
    "                    img3 = TF.adjust_contrast(img3,contrast_factor=.4)\n",
    "                if random.random()<.5:\n",
    "                    img = TF.adjust_gamma(img,gamma=1.4)\n",
    "                    img2 = TF.adjust_gamma(img2,gamma=1.4)\n",
    "                    img3 = TF.adjust_gamma(img3,gamma=1.4)\n",
    "                if random.random()<.5:\n",
    "                    trans = T.Grayscale(num_output_channels=3)\n",
    "                    img = trans(img)\n",
    "                    img2 = trans(img2)\n",
    "                    img3 = trans(img3)\n",
    "                if random.random()<.0:\n",
    "                    trans = T.ColorJitter(brightness=0.2, contrast=0.2, hue=0.2)\n",
    "                    img = trans(img)\n",
    "                    img2 = trans(img2)\n",
    "                    img3 = trans(img3)\n",
    "        \n",
    "        if self.transform!='test':\n",
    "            im_size = 256\n",
    "            trans = T.Resize((im_size,im_size))\n",
    "            img = trans(img)\n",
    "            img2 = trans(img2)\n",
    "            img3 = trans(img3)\n",
    "\n",
    "        if self.transform!=\"test\": mask = trans(mask)\n",
    "        print(type(img))\n",
    "        img.show()\n",
    "        img2.show()\n",
    "        img3.show()\n",
    "        trans = T.ToTensor()\n",
    "        img = trans(img)\n",
    "        img2 = trans(img2)\n",
    "        img3 = trans(img3)\n",
    "        if self.transform!=\"test\":\n",
    "            mask = np.array(mask) #to array\n",
    "            mask = (mask > 200) #background zero. 1-mask\n",
    "            mask = mask[:,:,0]\n",
    "            mask=scipy.ndimage.distance_transform_edt(mask) #creating distance map\n",
    "            mask[mask>20] = 20 #Cliping the distance map\n",
    "            mask = trans(mask)\n",
    "        \n",
    "        #VGG16 mean and std \n",
    "        meanR, meanG, meanB = .485,.456,.406\n",
    "        stdR, stdG, stdB = .229, .224, .225 \n",
    "        norm_= T.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])\n",
    "        img = norm_(img)\n",
    "        img2 = norm_(img2)\n",
    "        img3 = norm_(img3)\n",
    "        \n",
    "        if self.transform!='test':\n",
    "            return (img , img2 , img3), mask\n",
    "        else:\n",
    "            return (img , img2 , img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2d87ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64c902bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=open_dataset(path2train_i , path2train_i2 , path2train_i3 , path2data_m=path2train_m, transform='train')\n",
    "valid_ds=open_dataset(path2valid_i , path2valid_i2 , path2valid_i3 , path2data_m=path2valid_m, transform='val')\n",
    "test_ds=open_dataset(path2test_i , path2test_i2 , path2test_i3, path2data_m=path2test_m, transform='val')\n",
    "\n",
    "#Create Data Loader\n",
    "train_dl = DataLoader(train_ds, batch_size=3, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=3, shuffle=False) \n",
    "test_dl = DataLoader(test_ds, batch_size=3, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e6850a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4ec7b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13155"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ea0c2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((tensor([[[1.9920, 1.9920, 1.9920,  ..., 1.9407, 1.9407, 1.9407],\n",
       "           [1.9920, 1.9920, 1.9920,  ..., 1.9578, 1.9578, 1.9578],\n",
       "           [1.9920, 1.9920, 1.9920,  ..., 1.9578, 1.9578, 1.9578],\n",
       "           ...,\n",
       "           [2.0092, 2.0092, 2.0092,  ..., 1.9920, 1.9920, 1.9920],\n",
       "           [2.0092, 2.0092, 2.0092,  ..., 1.9920, 1.9920, 1.9920],\n",
       "           [2.0263, 2.0263, 2.0263,  ..., 1.9920, 1.9920, 1.9920]],\n",
       "  \n",
       "          [[2.1660, 2.1660, 2.1660,  ..., 2.1134, 2.1134, 2.1134],\n",
       "           [2.1660, 2.1660, 2.1660,  ..., 2.1310, 2.1310, 2.1310],\n",
       "           [2.1660, 2.1660, 2.1660,  ..., 2.1310, 2.1310, 2.1310],\n",
       "           ...,\n",
       "           [2.1835, 2.1835, 2.1835,  ..., 2.1660, 2.1660, 2.1660],\n",
       "           [2.1835, 2.1835, 2.1835,  ..., 2.1660, 2.1660, 2.1660],\n",
       "           [2.2010, 2.2010, 2.2010,  ..., 2.1660, 2.1660, 2.1660]],\n",
       "  \n",
       "          [[2.3786, 2.3786, 2.3786,  ..., 2.3263, 2.3263, 2.3263],\n",
       "           [2.3786, 2.3786, 2.3786,  ..., 2.3437, 2.3437, 2.3437],\n",
       "           [2.3786, 2.3786, 2.3786,  ..., 2.3437, 2.3437, 2.3437],\n",
       "           ...,\n",
       "           [2.3960, 2.3960, 2.3960,  ..., 2.3786, 2.3786, 2.3786],\n",
       "           [2.3960, 2.3960, 2.3960,  ..., 2.3786, 2.3786, 2.3786],\n",
       "           [2.4134, 2.4134, 2.4134,  ..., 2.3786, 2.3786, 2.3786]]]),\n",
       "  tensor([[[-0.6965, -0.6965, -0.6965,  ..., -0.6965, -0.6965, -0.6965],\n",
       "           [-0.7137, -0.6965, -0.6965,  ..., -0.6965, -0.6965, -0.6965],\n",
       "           [-0.7137, -0.6965, -0.6965,  ..., -0.6965, -0.6965, -0.6965],\n",
       "           ...,\n",
       "           [-0.6623, -0.6452, -0.6452,  ..., -0.6452, -0.6452, -0.6452],\n",
       "           [-0.6623, -0.6452, -0.6452,  ..., -0.6452, -0.6452, -0.6452],\n",
       "           [-0.6623, -0.6623, -0.6623,  ..., -0.6452, -0.6452, -0.6452]],\n",
       "  \n",
       "          [[-0.5826, -0.5826, -0.5826,  ..., -0.5826, -0.5826, -0.5826],\n",
       "           [-0.6001, -0.5826, -0.5826,  ..., -0.5826, -0.5826, -0.5826],\n",
       "           [-0.6001, -0.5826, -0.5826,  ..., -0.5826, -0.5826, -0.5826],\n",
       "           ...,\n",
       "           [-0.5476, -0.5301, -0.5301,  ..., -0.5301, -0.5301, -0.5301],\n",
       "           [-0.5476, -0.5301, -0.5301,  ..., -0.5301, -0.5301, -0.5301],\n",
       "           [-0.5476, -0.5476, -0.5476,  ..., -0.5301, -0.5301, -0.5301]],\n",
       "  \n",
       "          [[-0.3578, -0.3578, -0.3578,  ..., -0.3578, -0.3578, -0.3578],\n",
       "           [-0.3753, -0.3578, -0.3578,  ..., -0.3578, -0.3578, -0.3578],\n",
       "           [-0.3753, -0.3578, -0.3578,  ..., -0.3578, -0.3578, -0.3578],\n",
       "           ...,\n",
       "           [-0.3230, -0.3055, -0.3055,  ..., -0.3055, -0.3055, -0.3055],\n",
       "           [-0.3230, -0.3055, -0.3055,  ..., -0.3055, -0.3055, -0.3055],\n",
       "           [-0.3230, -0.3230, -0.3230,  ..., -0.3055, -0.3055, -0.3055]]]),\n",
       "  tensor([[[1.9920, 2.0092, 2.0092,  ..., 2.0092, 2.0092, 2.0092],\n",
       "           [1.9920, 2.0092, 2.0092,  ..., 2.0092, 2.0092, 2.0092],\n",
       "           [1.9920, 2.0092, 2.0092,  ..., 2.0092, 2.0092, 2.0092],\n",
       "           ...,\n",
       "           [2.0263, 2.0092, 2.0092,  ..., 2.0263, 2.0263, 2.0263],\n",
       "           [2.0263, 2.0092, 2.0092,  ..., 2.0263, 2.0263, 2.0263],\n",
       "           [2.0434, 2.0092, 2.0092,  ..., 2.0263, 2.0263, 2.0263]],\n",
       "  \n",
       "          [[2.1660, 2.1835, 2.1835,  ..., 2.1835, 2.1835, 2.1835],\n",
       "           [2.1660, 2.1835, 2.1835,  ..., 2.1835, 2.1835, 2.1835],\n",
       "           [2.1660, 2.1835, 2.1835,  ..., 2.1835, 2.1835, 2.1835],\n",
       "           ...,\n",
       "           [2.2010, 2.1835, 2.1835,  ..., 2.2010, 2.2010, 2.2010],\n",
       "           [2.2010, 2.1835, 2.1835,  ..., 2.2010, 2.2010, 2.2010],\n",
       "           [2.2185, 2.1835, 2.1835,  ..., 2.2010, 2.2010, 2.2010]],\n",
       "  \n",
       "          [[2.3786, 2.3960, 2.3960,  ..., 2.3960, 2.3960, 2.3960],\n",
       "           [2.3786, 2.3960, 2.3960,  ..., 2.3960, 2.3960, 2.3960],\n",
       "           [2.3786, 2.3960, 2.3960,  ..., 2.3960, 2.3960, 2.3960],\n",
       "           ...,\n",
       "           [2.4134, 2.3960, 2.3960,  ..., 2.4134, 2.4134, 2.4134],\n",
       "           [2.4134, 2.3960, 2.3960,  ..., 2.4134, 2.4134, 2.4134],\n",
       "           [2.4308, 2.3960, 2.3960,  ..., 2.4134, 2.4134, 2.4134]]])),\n",
       " tensor([[[20., 20., 20.,  ..., 20., 20., 20.],\n",
       "          [20., 20., 20.,  ..., 20., 20., 20.],\n",
       "          [20., 20., 20.,  ..., 20., 20., 20.],\n",
       "          ...,\n",
       "          [20., 20., 20.,  ..., 20., 20., 20.],\n",
       "          [20., 20., 20.,  ..., 20., 20., 20.],\n",
       "          [20., 20., 20.,  ..., 20., 20., 20.]]], dtype=torch.float64))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24d95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a24dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Im_Seg_3(torch.nn.Module):\n",
    "    def __init__(self ,device, loc = \"./models/\" , trainable = set()):\n",
    "        super().__init__()\n",
    "        self.a = torch.nn.Parameter(torch.tensor(0.6) , requires_grad=True)\n",
    "        self.b = torch.nn.Parameter(torch.tensor(0.2) , requires_grad=True)\n",
    "        self.c = torch.nn.Parameter(torch.tensor(0.2) , requires_grad=True)\n",
    "        #self.d = torch.nn.Parameter(torch.randn(()) , requires_grad=True)\n",
    "        self.mod1 = UNet16() \n",
    "        self.mod2 = UNet16() \n",
    "        self.mod3 = UNet16() \n",
    "        self.mod1.to(device = device)\n",
    "        self.mod2.to(device = device)\n",
    "        self.mod3.to(device = device)\n",
    "        print(\"Reading model 1\")\n",
    "        self.mod1.load_state_dict(torch.load(loc + \"model1.pt\", map_location=device))\n",
    "        print(\"Reading model 2\")\n",
    "        self.mod2.load_state_dict(torch.load(loc + \"model2.pt\", map_location=device))\n",
    "        print(\"Reading model 3\")\n",
    "        self.mod3.load_state_dict(torch.load(loc + \"model3.pt\", map_location=device))\n",
    "        for k in self.mod1.named_parameters():\n",
    "            k[1].requires_grad = True if k[0].split(\".\")[0] in trainable else False\n",
    "        for k in self.mod2.named_parameters():\n",
    "            k[1].requires_grad = True if k[0].split(\".\")[0] in trainable else False  \n",
    "        for k in self.mod3.named_parameters():\n",
    "            k[1].requires_grad = True if k[0].split(\".\")[0] in trainable else False  \n",
    "\n",
    "        #print(self.a.requires_grad , self.b.requires_grad , self.c.requires_grad)\n",
    "\n",
    "        #self.a.requires_grad = True \n",
    "        #self.b.requires_grad = True \n",
    "        #self.c.requires_grad = True \n",
    "        #print(len(list(self.check_state(1))) ,len(list(self.check_state(2))) , len(list(self.check_state(3))) )\n",
    "    def check_state(self , mod):\n",
    "        dic = {1 : self.mod1 , 2 : self.mod2 , 3 : self.mod3 }\n",
    "        return dic[mod].named_parameters()\n",
    "    \n",
    "    def forward(self , inp1 , inp2 ,inp3):\n",
    "        #print(\"Yes , Yes , Yes\")\n",
    "        ss = self.a + self.b + self.c\n",
    "        self.a = self.a/float(ss)\n",
    "        self.b = self.b/float(ss)\n",
    "        self.c = self.c/float(ss)\n",
    "        out1 = self.mod1(inp1)\n",
    "        out2 = self.mod2(inp2)\n",
    "        out3 = self.mod3(inp3)\n",
    "        #return float(20.0)*torch.sigmoid(out1 + out2 + out3)\n",
    "        return self.a*out1 + self.b*out2 + self.c*out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb64998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\topo_crack_detection\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e817b26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(0.3897, requires_grad=True)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Parameter(torch.randn(()) , requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "352863e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(0.6000, requires_grad=True)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Parameter(torch.tensor(0.6) , requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9a1d88d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.nn.parameter.Parameter(torch.Tensor([0.5 , 0.5 , 0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "54a600ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3333, 0.3333, 0.3333], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(m , dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "bb013622",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): data must be a sequence (got float)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15056\\1281519423.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: new(): data must be a sequence (got float)"
     ]
    }
   ],
   "source": [
    "torch.Tensor([0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "777facbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(size = (3,256,256)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b38d26eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(size = (3 ,256,256,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efb7bead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256, 256, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba34c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7598c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "892d796f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (5) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15132\\1595439524.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (5) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "torch.matmul(torch.ones((3 , 256 ,256 ,1)) , x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d170acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.zeros(size = (2,4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a667e288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "99659024",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = -1*torch.ones(size = (2, 4 ,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e79ccbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a850b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.stack((x,y,z) , dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3e149bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3, 5])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4000cd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  1.,  1.,  1.,  1.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.],\n",
       "         [-1., -1., -1., -1., -1.]],\n",
       "\n",
       "        [[ 1.,  1.,  1.,  1.,  1.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.],\n",
       "         [-1., -1., -1., -1., -1.]],\n",
       "\n",
       "        [[ 1.,  1.,  1.,  1.,  1.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.],\n",
       "         [-1., -1., -1., -1., -1.]],\n",
       "\n",
       "        [[ 1.,  1.,  1.,  1.,  1.],\n",
       "         [ 0.,  0.,  0.,  0.,  0.],\n",
       "         [-1., -1., -1., -1., -1.]]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "feb1f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.nn.parameter.Parameter(torch.Tensor([0.5 , 0.5 , 0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f1b6adfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9a1e95cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = torch.vstack((m ,m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8816ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = m1.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "00e136dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2226007f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3, 5])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "feec3e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = torch.ones((2,3,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "df6f6338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5, 1])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.ones((2,4,5,3)) , torch.ones((2,4,3,1 )) ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fe5f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[[1, 2],\n",
    "                   [3, 4]],\n",
    "                   [[5, 6],\n",
    "                    [7, 8]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95a9adc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ece61dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a80af496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e71bdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(t, start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54bfc5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(t, start_dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "722cb3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = torch.ones((5 ,3 ,4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f764b779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 65536]),\n",
       " tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(tt, start_dim=1).shape , torch.flatten(tt, start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "edfbd90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt  = torch.stack((torch.flatten(tt, start_dim=1) , torch.flatten(tt, start_dim=1) ,torch.flatten(tt, start_dim=1)) , dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1688875c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 65536, 3])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "285f8478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5076f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(ttt , torch.ones(()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e4e10abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 12])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(tt, start_dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c74a9b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(tt, start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f0349461",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = torch.arange(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5b433ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccc = torch.reshape(cc, (3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "64ba4ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cccc = torch.reshape(ccc, (12,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bb70138f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]),\n",
       " tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]]),\n",
       " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc , ccc ,cccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fc92f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a0d0bcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 12])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(tt, start_dim=1).unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "faf642be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = torch.mul(torch.flatten(tt, start_dim=1).unsqueeze(1) , torch.arange(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4cbc6086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]],\n",
       "\n",
       "        [[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]],\n",
       "\n",
       "        [[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]],\n",
       "\n",
       "        [[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]],\n",
       "\n",
       "        [[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e5b1d356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.]]],\n",
       "\n",
       "\n",
       "        [[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.]]]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.reshape(ii, (5,1,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b71671b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = torch.ones((3, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ee3579c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r[0][0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3bf34bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ec19ba6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1554, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333,\n",
       "         0.3333, 0.3333, 0.3333],\n",
       "        [0.4223, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333,\n",
       "         0.3333, 0.3333, 0.3333],\n",
       "        [0.4223, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333,\n",
       "         0.3333, 0.3333, 0.3333]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(r , dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0ab66996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65536])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3 , 256*256).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3a1b3995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 256, 256])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(5 ,1, 256,256).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3a920ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 65536])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(torch.randn(5 ,1, 256,256) , start_dim = 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b8e6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\topo_crack_detection\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import numpy as np\n",
    "#from torchinfo import summary\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision import transforms\n",
    "from network import UNet16\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class param_net(torch.nn.Module):\n",
    "    def __init__(self , device , dim = 256):\n",
    "        super().__init__()\n",
    "        net = models.vgg16_bn(pretrained = False)\n",
    "        self.mm1 = torch.nn.Sequential(*list(net.features.children())[0:20] , torch.nn.flatten())\n",
    "        self.mm2 = torch.nn.Sequential(*list(net.features.children())[0:20] , torch.nn.flatten())\n",
    "        self.mm3 = torch.nn.Sequential(*list(net.features.children())[0:20] , torch.nn.flatten())\n",
    "        self.mm1.to(device)   \n",
    "        self.mm2.to(device)\n",
    "        self.mm3.to(device)\n",
    "        self.dim = dim\n",
    "        self.lin1 = torch.nn.Linear(in_features=3*64*64*256,out_features=dim*dim*8,bias=True)\n",
    "        self.lin2 = torch.nn.Linear(in_features=dim*dim*8,out_features=dim*dim*4,bias=True)\n",
    "        self.lin3 = torch.nn.Linear(in_features=dim*dim*8,out_features=dim*dim*4,bias=True)\n",
    "        self.lin4 = torch.nn.Linear(in_features=dim*dim*4,out_features=dim*dim*2,bias=True)\n",
    "        self.lin5 = torch.nn.Linear(in_features=dim*dim*2,out_features=dim*dim,bias=True)\n",
    "        self.seq =  torch.nn.Sequential(self.lin1,\n",
    "                                        torch.nn.ReLU() , \n",
    "                                        self.lin2 ,\n",
    "                                        torch.nn.ReLU() , \n",
    "                                        self.lin3,\n",
    "                                        torch.nn.ReLU()  ,\n",
    "                                        self.lin4 ,\n",
    "                                        torch.nn.ReLU() , \n",
    "                                        self.lin5 , \n",
    "                                        torch.nn.ReLU())\n",
    "        \n",
    "    def forward(self , inp1 , inp2 , inp3):\n",
    "        mm1_out = self.mm1(inp1)\n",
    "        mm2_out = self.mm2(inp2)\n",
    "        mm3_out = self.mm3(inp3)\n",
    "        cat_out = torch.cat((mm1_out, mm2_out, mm3_out), 1)\n",
    "        return self.seq(cat_out)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "class Im_Seg_4(torch.nn.Module):\n",
    "    def __init__(self ,device, loc = \"./models/\" , trainable = set() , dim = 256):\n",
    "        super().__init__()\n",
    "        #self.a = torch.nn.Parameter(torch.randn(3 , dim*dim) , requires_grad=True)\n",
    "        self.mod1 = UNet16() \n",
    "        self.mod2 = UNet16() \n",
    "        self.mod3 = UNet16() \n",
    "        self.mod1.to(device = device)\n",
    "        self.mod2.to(device = device)\n",
    "        self.mod3.to(device = device)\n",
    "        print(\"Reading model 1\")\n",
    "        self.mod1.load_state_dict(torch.load(loc + \"model1.pt\", map_location=device))\n",
    "        print(\"Reading model 2\")\n",
    "        self.mod2.load_state_dict(torch.load(loc + \"model2.pt\", map_location=device))\n",
    "        print(\"Reading model 3\")\n",
    "        self.mod3.load_state_dict(torch.load(loc + \"model3.pt\", map_location=device))\n",
    "        for k in self.mod1.named_parameters():\n",
    "            k[1].requires_grad = True if k[0].split(\".\")[0] in trainable else False\n",
    "        for k in self.mod2.named_parameters():\n",
    "            k[1].requires_grad = True if k[0].split(\".\")[0] in trainable else False  \n",
    "        for k in self.mod3.named_parameters():\n",
    "            k[1].requires_grad = True if k[0].split(\".\")[0] in trainable else False  \n",
    "            \n",
    "    def get_param_net(self , device , dim = 256):\n",
    "        net = models.vgg16_bn(pretrained = False)\n",
    "        mm1 = torch.nn.Sequential(*list(net.features.children())[0:20] , torch.nn.flatten())\n",
    "        mm2 = torch.nn.Sequential(*list(net.features.children())[0:20] , torch.nn.flatten())\n",
    "        mm3 = torch.nn.Sequential(*list(net.features.children())[0:20] , torch.nn.flatten())\n",
    "        mm1.to(device)   \n",
    "        mm2.to(device)\n",
    "        mm3.to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def check_state(self , mod):\n",
    "        dic = {1 : self.mod1 , 2 : self.mod2 , 3 : self.mod3 }\n",
    "        return dic[mod].named_parameters()\n",
    "    \n",
    "    def forward(self , inp1 , inp2 ,inp3):\n",
    "        new = torch.nn.functional.softmax(self.a , dim = 0)\n",
    "        out1 = self.mod1(inp1)\n",
    "        B , C ,H ,W = out1.shape\n",
    "        out2 = self.mod2(inp2)\n",
    "        out3 = self.mod3(inp3)\n",
    "        out1_flat = torch.flatten(out1 , start_dim=2)\n",
    "        out2_flat = torch.flatten(out2 , start_dim=2)\n",
    "        out3_flat = torch.flatten(out3 , start_dim=2)\n",
    "        out1_dot = torch.mul(out1_flat , new[0])\n",
    "        out2_dot = torch.mul(out2_flat , new[1])\n",
    "        out3_dot = torch.mul(out3_flat , new[2])\n",
    "        out_dot = out1_dot + out2_dot + out3_dot\n",
    "        return torch.reshape(out_dot ,(B,C,H,W) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f492e7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model 1\n",
      "Reading model 2\n",
      "Reading model 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Im_Seg_2(\n",
       "  (mod1): UNet16(\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (encoder): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv5): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (center): DecoderBlockV2(\n",
       "      (block): Sequential(\n",
       "        (0): Interpolate()\n",
       "        (1): ConvRelu(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvRelu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec5): DecoderBlockV2(\n",
       "      (block): Sequential(\n",
       "        (0): Interpolate()\n",
       "        (1): ConvRelu(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvRelu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec4): DecoderBlockV2(\n",
       "      (block): Sequential(\n",
       "        (0): Interpolate()\n",
       "        (1): ConvRelu(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvRelu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec3): DecoderBlockV2(\n",
       "      (block): Sequential(\n",
       "        (0): Interpolate()\n",
       "        (1): ConvRelu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvRelu(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec2): DecoderBlockV2(\n",
       "      (block): Sequential(\n",
       "        (0): Interpolate()\n",
       "        (1): ConvRelu(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvRelu(\n",
       "          (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec1): ConvRelu(\n",
       "      (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (final): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (final2): Sigmoid()\n",
       "  )\n",
       "  (mod2): UNet16(\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (encoder): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv5): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (center): DecoderBlockV2(\n",
       "      (block): Sequential(\n",
       "        (0): Interpolate()\n",
       "        (1): ConvRelu(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvRelu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec5): DecoderBlockV2(\n",
       "      (block): Sequential(\n",
       "        (0): Interpolate()\n",
       "        (1): ConvRelu(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvRelu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec4): DecoderBlockV2(\n",
       "      (block): Sequential(\n",
       "        (0): Interpolate()\n",
       "        (1): ConvRelu(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvRelu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec3): DecoderBlockV2(\n",
       "      (block): Sequential(\n",
       "        (0): Interpolate()\n",
       "        (1): ConvRelu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvRelu(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec2): DecoderBlockV2(\n",
       "      (block): Sequential(\n",
       "        (0): Interpolate()\n",
       "        (1): ConvRelu(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvRelu(\n",
       "          (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec1): ConvRelu(\n",
       "      (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (final): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (final2): Sigmoid()\n",
       "  )\n",
       "  (mod3): UNet16(\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (encoder): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv5): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (center): DecoderBlockV2(\n",
       "      (block): Sequential(\n",
       "        (0): Interpolate()\n",
       "        (1): ConvRelu(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvRelu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec5): DecoderBlockV2(\n",
       "      (block): Sequential(\n",
       "        (0): Interpolate()\n",
       "        (1): ConvRelu(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvRelu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec4): DecoderBlockV2(\n",
       "      (block): Sequential(\n",
       "        (0): Interpolate()\n",
       "        (1): ConvRelu(\n",
       "          (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvRelu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec3): DecoderBlockV2(\n",
       "      (block): Sequential(\n",
       "        (0): Interpolate()\n",
       "        (1): ConvRelu(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvRelu(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec2): DecoderBlockV2(\n",
       "      (block): Sequential(\n",
       "        (0): Interpolate()\n",
       "        (1): ConvRelu(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvRelu(\n",
       "          (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dec1): ConvRelu(\n",
       "      (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (final): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (final2): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Im_Seg_2(torch.device('cuda'))\n",
    "model.to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ceb8a5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 256, 256])\n",
      "torch.Size([5, 1, 256, 256])\n",
      "torch.Size([5, 1, 256, 256])\n",
      "torch.Size([5, 1, 65536]) torch.Size([5, 1, 65536]) torch.Size([5, 1, 65536]) torch.Size([65536])\n",
      "torch.Size([5, 1, 65536]) torch.Size([5, 1, 65536]) torch.Size([5, 1, 65536])\n"
     ]
    }
   ],
   "source": [
    "up = model(torch.randn(5,3 ,256,256).to(torch.device('cuda')) ,torch.randn(5,3 ,256,256).to(torch.device('cuda')) , torch.randn(5,3 ,256,256).to(torch.device('cuda')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f85475a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "80b3f6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 256, 256])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8afd6a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.vgg16_bn(pretrained = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2c2d572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): ReLU(inplace=True)\n",
       "  (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): ReLU(inplace=True)\n",
       "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (16): ReLU(inplace=True)\n",
       "  (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (19): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm = torch.nn.Sequential(*list(net.features.children())[0:20])\n",
    "mm.to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0246a413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "            Conv2d-4         [-1, 64, 256, 256]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 256, 256]             128\n",
      "              ReLU-6         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-7         [-1, 64, 128, 128]               0\n",
      "            Conv2d-8        [-1, 128, 128, 128]          73,856\n",
      "       BatchNorm2d-9        [-1, 128, 128, 128]             256\n",
      "             ReLU-10        [-1, 128, 128, 128]               0\n",
      "           Conv2d-11        [-1, 128, 128, 128]         147,584\n",
      "      BatchNorm2d-12        [-1, 128, 128, 128]             256\n",
      "             ReLU-13        [-1, 128, 128, 128]               0\n",
      "        MaxPool2d-14          [-1, 128, 64, 64]               0\n",
      "           Conv2d-15          [-1, 256, 64, 64]         295,168\n",
      "      BatchNorm2d-16          [-1, 256, 64, 64]             512\n",
      "             ReLU-17          [-1, 256, 64, 64]               0\n",
      "           Conv2d-18          [-1, 256, 64, 64]         590,080\n",
      "      BatchNorm2d-19          [-1, 256, 64, 64]             512\n",
      "             ReLU-20          [-1, 256, 64, 64]               0\n",
      "================================================================\n",
      "Total params: 1,147,200\n",
      "Trainable params: 1,147,200\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 348.00\n",
      "Params size (MB): 4.38\n",
      "Estimated Total Size (MB): 353.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(mm , input_size = (3 ,256 ,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad75efe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
