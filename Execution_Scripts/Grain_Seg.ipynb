{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26e11dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0088443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from skimage.morphology import thin\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os \n",
    "import time\n",
    "\n",
    "from predict_filter_mirror_aug_overtile import topredict_filter_Mirror_Aug_overtiles\n",
    "from predict_tiles import predict_tiles\n",
    "from combine_fractions import combine_fractions\n",
    "from ensemble_vote_fill import ensemble_vote_fill\n",
    "from vote_fill_thin_second import vote_fill_thin_second, border_thinning\n",
    "import reverse as reverse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e5f0e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'example11' \n",
    "img_name = 'img.jpeg'\n",
    "dir_raw = './data/' + run_name + '/'\n",
    "\n",
    "\n",
    "# Dirs_prediction\n",
    "\n",
    "prediction_mid = './prediction/' + run_name + '/1-Mid_Results' \n",
    "prediction_final = './prediction/' + run_name + '/2-Final_Results' \n",
    "fullimg_raw = './prediction/'  + run_name+ '/0-Full/Full_raw/'\n",
    "dir_aug_full = './prediction/' + run_name + './0-Full/Full_aug/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f15e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Model parameters\n",
    "GLOBAL = {\n",
    "    ###############\n",
    "    #Operation\n",
    "    ###############\n",
    "    'Stage_predicting' : True,\n",
    "    'shift' : False,\n",
    "    \n",
    "    #########################################\n",
    "    # Fix arguments\n",
    "    #########################################\n",
    "       \n",
    "    # Dir_Model\n",
    "    'dir_model': 'Models/final_model.pt',    \n",
    "    #Aug_dirs\n",
    "    'aug_list' : ['rt00', 'rt90', 'rt180', 'fplr', 'fpud'],\n",
    "    # 'aug_list' : ['rt00', 'rt90', 'fpud'],\n",
    "    #vote_filled_dir\n",
    "    'vote_filled_dir' : '1 - voted_filled_full',\n",
    "    # size of picture samples\n",
    "    'len_img_samples-1' : 256,\n",
    "    'len_img_samples-2' : 512,   \n",
    "    'len_img_samples-3' : 1024,\n",
    "    #Vote : if vote = 2, then one a pixel will be considered as interstice once there are two (out of five) ensemble predictions shows negative value (interstice) in that pixel\n",
    "    'vote_threshold' : 1,\n",
    "    # Interstice thinning\n",
    "    'thin_inters' : 2,\n",
    "    'thin_inters_benchmark' : 2,\n",
    "    'type' : 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf0a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "680bcdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_sizes_dict =  topredict_filter_Mirror_Aug_overtiles(dir_raw, #  /data/example/\n",
    "#                                                               fullimg_raw, #/prediction/example/0-Full/Full_raw/\n",
    "#                                                               dir_aug_full, #'/prediction/example/0-Full/Full_aug/'\n",
    "#                                                               prediction_mid, #'/prediction/example/1-Mid_Results' \n",
    "#                                                               GLOBAL['aug_list'], #['rt00', 'rt90', 'rt180', 'fplr', 'fpud']\n",
    "#                                                               GLOBAL['len_img_samples-2'],#512\n",
    "#                                                               img_name) #'img.jpg'\n",
    "# print(\"Done!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf0111a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_sizes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e159c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_tiles(GLOBAL['dir_model'], #'./Tiles_512_Sigmod6CT_ep150.pth'\n",
    "#                   prediction_mid,#'/prediction/example/1-Mid_Results'\n",
    "#                   GLOBAL['aug_list'])#['rt00', 'rt90', 'rt180', 'fplr', 'fpud']\n",
    "# print(\"Done!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95e16b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k , v in image_sizes_dict.items() :\n",
    "#     image_sizes_dict[k] = image_sizes_dict[k][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6387fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_sizes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48952628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine_fractions(prediction_mid, #'/prediction/example/1-Mid_Results'\n",
    "#                       GLOBAL['aug_list'],#['rt00', 'rt90', 'rt180', 'fplr', 'fpud']\n",
    "#                       GLOBAL['len_img_samples-2'], #512\n",
    "#                       image_sizes_dict) # (output of (1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc98f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble_vote_fill(prediction_mid, #'/prediction/example/1-Mid_Results'\n",
    "#                        prediction_final, #'/prediction/example/2-Final_Results' \n",
    "#                        GLOBAL['aug_list'], #['rt00', 'rt90', 'rt180', 'fplr', 'fpud']\n",
    "#                        GLOBAL['vote_threshold']) #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af111426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2534016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples_aug_predict_combine_vote_fill():\n",
    "#%% 1 - Create Samples\n",
    "    print(\"1 - preparing!!!\")\n",
    "    image_sizes_dict =  topredict_filter_Mirror_Aug_overtiles(dir_raw, #  /data/example/\n",
    "                                                              fullimg_raw, #/prediction/example/0-Full/Full_raw/\n",
    "                                                              dir_aug_full, #'/prediction/example/0-Full/Full_aug/'\n",
    "                                                              prediction_mid, #'/prediction/example/1-Mid_Results' \n",
    "                                                              GLOBAL['aug_list'], #['rt00', 'rt90', 'rt180', 'fplr', 'fpud']\n",
    "                                                              GLOBAL['len_img_samples-2'],#512\n",
    "                                                              img_name) #'img.jpg'\n",
    "    \n",
    "    \n",
    "    #%% 2 - Predicting\n",
    "    print(\"2 - predicting!!!\")\n",
    "    predict_tiles(GLOBAL['dir_model'], #'./Tiles_512_Sigmod6CT_ep150.pth'\n",
    "                  prediction_mid,#'/prediction/example/1-Mid_Results'\n",
    "                  GLOBAL['aug_list'] , GLOBAL['type'])#['rt00', 'rt90', 'rt180', 'fplr', 'fpud']\n",
    "    \n",
    "    for k , v in image_sizes_dict.items() :\n",
    "        image_sizes_dict[k] = image_sizes_dict[k][0]\n",
    "    \n",
    "    #%% 3 - Combine Fraction\n",
    "    print(\"3 - combining!!!\")\n",
    "    combine_fractions(prediction_mid, #'/prediction/example/1-Mid_Results'\n",
    "                      GLOBAL['aug_list'],#['rt00', 'rt90', 'rt180', 'fplr', 'fpud']\n",
    "                      GLOBAL['len_img_samples-2'], #512\n",
    "                      image_sizes_dict) # (output of (1))\n",
    "    \n",
    "\n",
    "    #%% 4 - Vote\n",
    "    '''\n",
    "    If vote = 2 , it means if two prediction (five) shows there should be interstice, then mark it as edge.\n",
    "    '''\n",
    "    print(\"4 - voting&post-processing!!!\")\n",
    "    ensemble_vote_fill(prediction_mid, #'/prediction/example/1-Mid_Results'\n",
    "                       prediction_final, #'/prediction/example/2-Final_Results' \n",
    "                       GLOBAL['aug_list'], #['rt00', 'rt90', 'rt180', 'fplr', 'fpud']\n",
    "                       GLOBAL['vote_threshold']) #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32c8345f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - preparing!!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e76b4a1652d4dd9851a8e561494975b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Num_Images:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - predicting!!!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d428c6bd2b146a69d7797eab98497aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "augmentations:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\torch_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\torch_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model 1\n",
      "Reading model 2\n",
      "Reading model 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0618a832adf1451b8d39f51713fbe3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Num_Image:   0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\torch_env\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model 1\n",
      "Reading model 2\n",
      "Reading model 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ced6f55f2e14396afe1acfdae282650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Num_Image:   0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model 1\n",
      "Reading model 2\n",
      "Reading model 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ebad6a04084d3e88c7c0e29c118db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Num_Image:   0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model 1\n",
      "Reading model 2\n",
      "Reading model 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee60660b36cd43c1a3d5ee7c0e6aa297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Num_Image:   0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model 1\n",
      "Reading model 2\n",
      "Reading model 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d8e6e4e6fe43f5ad816c8fcfa5b98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Num_Image:   0%|          | 0/720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "starttime = time.time()   \n",
    "create_samples_aug_predict_combine_vote_fill()     \n",
    "endtime = time.time()\n",
    "print(endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ee3b296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\torch_env\\lib\\site-packages\\PIL\\Image.py:3167: DecompressionBombWarning: Image size (96657764 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserting ./prediction/example2/1-Mid_Results\\rt00_pred_Full\\MC16_S1.png\n",
      "inserting ./prediction/example2/1-Mid_Results\\rt90_pred_Full\\MC16_S1.png\n",
      "inserting ./prediction/example2/1-Mid_Results\\rt180_pred_Full\\MC16_S1.png\n",
      "inserting ./prediction/example2/1-Mid_Results\\fplr_pred_Full\\MC16_S1.png\n",
      "inserting ./prediction/example2/1-Mid_Results\\fpud_pred_Full\\MC16_S1.png\n",
      "inserting ./prediction/example2/1-Mid_Results\\rt00_pred_Full\\MC16_S2.png\n",
      "inserting ./prediction/example2/1-Mid_Results\\rt90_pred_Full\\MC16_S2.png\n",
      "inserting ./prediction/example2/1-Mid_Results\\rt180_pred_Full\\MC16_S2.png\n",
      "inserting ./prediction/example2/1-Mid_Results\\fplr_pred_Full\\MC16_S2.png\n",
      "inserting ./prediction/example2/1-Mid_Results\\fpud_pred_Full\\MC16_S2.png\n"
     ]
    }
   ],
   "source": [
    "ensemble_vote_fill(prediction_mid, #'/prediction/example/1-Mid_Results'\n",
    "                       prediction_final, #'/prediction/example/2-Final_Results' \n",
    "                       GLOBAL['aug_list'], #['rt00', 'rt90', 'rt180', 'fplr', 'fpud']\n",
    "                       GLOBAL['vote_threshold']) #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9b88c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
